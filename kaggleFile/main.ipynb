{"cells":[{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# ========= hyper parameters =========\n","num_epochs = 150\n","batch_size = 64\n","num_workers = 2\n","\n","# choose path, dataset, model\n","run_on_local = 0 # 1 for True, 0 for False\n","dataset1 = 'CIFAR10' # choose between 'MNIST' or 'CIFAR10'\n","model_id = -1 # 0/2/4/6/8/10 for MNIST, 1/3/5/7/9/11 for CIFAR10\n","# 2025-3-8 running: resenet18 and cgg16 on cifar10 v/v4\n","modelnames = ['C3L2_MNIST', 'C3L2_cifar10', 'C5L3_MNIST', 'C5L3_cifar10', 'ResNet18_MNIST', 'ResNet18_cifar10' ,'ResNet20_MNIST', 'ResNet20_cifar10', 'ResNet50_MNIST', 'ResNet50_cifar10', 'VGG16_MNIST', 'VGG16_cifar10', 'ResNet20_omni', 'C5L3_base_cifar10']\n","\n","optimizer_id = 0 # 0 for Adam, 1 for SGD\n","data_aug = False"]},{"cell_type":"code","execution_count":8,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["def main(num_epochs = num_epochs, batch_size = batch_size, num_workers = num_workers, run_on_local = run_on_local, dataset1 = dataset1, model_id = model_id, optimizer_id = optimizer_id, data_aug = data_aug, modelnames = modelnames):\n","    import torch\n","    import torch.nn as nn\n","    import torch.optim as optim\n","\n","    import torchvision.datasets as tv_datasets\n","    import torchvision.transforms as tv_transforms\n","    import numpy as np\n","\n","    # add kaggle dataset file to path /kaggle/input/training-scripts-dl-hw1\n","    import sys\n","\n","    # some experimental setup\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # device(type='cpu')\n","    kaggle = \"/kaggle/input/cifar-10-dlhw1-2/data\"\n","    local = \"../data\"\n","\n","    if run_on_local:\n","        data_path = local\n","        sys.path.append('./code')\n","        \n","    else:\n","        data_path = kaggle\n","        sys.path.append('/kaggle/input')\n","\n","    from mymodels import models\n","    print('successfully load all pac')\n","\n","\n","    optim_name = [\"Adam\", \"SGD\"]\n","    optim_kwargs = {\"Adam\": dict(lr=3e-4, weight_decay=1e-6,),\n","        \"SGD\": dict(lr = 1e-3, momentum = 0.9)}\n","\n","    if data_aug:\n","        # ============ MNIST transform with aug ===========\n","        if dataset1 == 'MNIST':\n","            transformation = dict()\n","            for data_type in (\"train\", \"test\"):\n","                is_train = data_type==\"train\"\n","                transformation[data_type] = tv_transforms.Compose(([\n","                tv_transforms.RandomRotation(15),  \n","                tv_transforms.RandomAffine(0, translate=(0.1, 0.1)),  \n","                # tv_transforms.RandomResizedCrop(28, scale=(0.9, 1.1)), \n","                tv_transforms.ToTensor(),  \n","                tv_transforms.Normalize((0.1307,), (0.3081,))  \n","            ] if is_train else [\n","                tv_transforms.ToTensor(),\n","                tv_transforms.Normalize((0.1307,), (0.3081,))]))\n","\n","        elif dataset1 == 'CIFAR10':\n","        # ============== cifar transform with aug ================\n","            transformation = dict()\n","            for data_type in (\"train\", \"test\"):\n","                is_train = data_type==\"train\"\n","                transformation[data_type] = tv_transforms.Compose((\n","                    [\n","                        \n","                        tv_transforms.RandomRotation(degrees=15),\n","                        tv_transforms.RandomHorizontalFlip(),\n","                        tv_transforms.RandomAffine(degree = 0, translate = (0.1, 0.1)),\n","                        tv_transforms.ColorJitter(\n","                            brightness=0.2, \n","                            contrast=0.2,\n","                            saturation=0.2,\n","                            hue=0.1\n","                        ),\n","                        \n","\n","                        tv_transforms.ToTensor(),\n","                        tv_transforms.Normalize(\n","                            mean=[0.4914, 0.4822, 0.4465],\n","                            std=[0.247, 0.243, 0.261]\n","                        )\n","                    ] if is_train else [\n","                        tv_transforms.ToTensor(),\n","                        tv_transforms.Normalize(\n","                            mean=[0.4914, 0.4822, 0.4465],\n","                            std=[0.247, 0.243, 0.261]\n","                        )\n","                    ]\n","                ))\n","\n","    # ============= transformation without data augmentation ==================\n","    else:\n","        if dataset1 == 'CIFAR10':\n","            transformation = dict()\n","            for data_type in ('train', 'test'):\n","                is_train = data_type == 'train'\n","                transformation[data_type] = tv_transforms.Compose(([\n","                tv_transforms.RandomRotation(degrees=15),\n","                tv_transforms.RandomHorizontalFlip(),\n","                tv_transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n","                tv_transforms.ToTensor(),\n","                tv_transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n","            ] if is_train else  [   \n","                tv_transforms.ToTensor(),\n","                tv_transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n","            ]))\n","        elif dataset1 == 'MNIST':\n","            transformation = dict()\n","            for data_type in ('train', 'test'):\n","                is_train = data_type == 'train'\n","                transformation[data_type] = tv_transforms.Compose(([\n","                tv_transforms.ToTensor(),  \n","                tv_transforms.Normalize((0.1307,), (0.3081,))  \n","            ] if is_train else  [   \n","                tv_transforms.ToTensor(),  \n","                tv_transforms.Normalize((0.1307,), (0.3081,))  \n","            ]))\n","\n","    # prepare datasets\n","    dataloader = getattr(tv_datasets, dataset1)\n","    dataset, loader = {}, {}\n","    for data_type in (\"train\", \"test\"):\n","        is_train = data_type==\"train\"\n","        # root=./data: create data file in root path if there is none, dataset size ~340MB\n","        # path kaggle: \"/kaggle/input/cifar-10-dlhw1/data\"\n","        # path local: \"../data\"\n","        dataset[data_type] = dataloader(\n","            root=data_path, train=is_train, download=True, transform=transformation[data_type],\n","        )\n","        loader[data_type] = torch.utils.data.DataLoader(\n","            dataset[data_type], batch_size=batch_size, shuffle=is_train, num_workers=num_workers\n","        )\n","\n","    # ======== training loop =========\n","    # modelnames = ['C3L2_MNIST', 'C3L2_cifar10', 'C5L3_MNIST', 'C5L3_cifar10', 'ResNet20_MNIST', 'ResNet20_cifar10']\n","    # use dummy input to initialize nn.LazyConv2d\n","    dummy_input = dataset['train'][0][0].unsqueeze(0)\n","    net = getattr(models, modelnames[model_id])\n","    net(dummy_input)\n","\n","    # move to device\n","    net.to(device)\n","\n","    # print the info of hyper/parameters\n","    # do not check parameter info before passing data into the model if you use LazyConv2d\n","    print(f'hyperparams: num_epochs: {num_epochs}, batch_size: {batch_size}, num_workers: {num_workers}, run_on_local: {run_on_local}, dataset: {dataset1}, model_id: {model_id}-{modelnames[model_id]}, optimizer_id: {optimizer_id}-{optim_name[optimizer_id]}, data_aug: {int(data_aug)}')\n","    print(f\"number of parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad) / 1_000_000:.2f}M\")\n","\n","    # the network optimizer\n","    optimizer = getattr(optim, optim_name[optimizer_id])(net.parameters(), **optim_kwargs[optim_name[optimizer_id]])\n","\n","    # loss function\n","    criterion = nn.CrossEntropyLoss()\n","\n","    # statistics:\n","    loss_train = []\n","    accuracy_test = []\n","\n","\n","    # training loop\n","    net.train()\n","    for epoch in range(num_epochs):\n","\n","        running_loss = 0.0\n","        for i, (img, target) in enumerate(loader[\"train\"]):\n","            img, target = img.to(device), target.to(device)\n","\n","            pred = net(img)\n","            loss = criterion(pred, target)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()/batch_size\n","\n","        # eval at each epoch: computation-consuming? i just don't care\n","        correct, total = 0, 0\n","        with torch.no_grad():\n","            for img, target in loader[\"test\"]:\n","                img, target = img.to(device), target.to(device)\n","                \n","                # make prediction\n","                pred = net(img)\n","                \n","                # accumulate\n","                total += len(target)\n","                correct += (torch.argmax(pred, dim=1) == target).sum().item()\n","                \n","        loss_train.append(running_loss)\n","        accuracy_test.append(correct / total)\n","        print(f\"Epchs: {epoch+1}, train loss: {loss_train[-1]:.2f}, test Accuracy: {100 * accuracy_test[-1]:.2f}%\")\n","\n","    print(\"Finished Training\")\n","\n","    # ===== save trained weights =====\n","    save_name = f'{modelnames[model_id]}_{optim_name[optimizer_id]}_{int(data_aug)}aug'\n","    PATH = '/kaggle/working/'+ 'weights_' + save_name +'.pth'\n","    torch.save(net.state_dict(), PATH)\n","\n","    # save accuracy/loss statistics\n","    np.save('stats_' + save_name+'_accuracy_test.npy', np.array(accuracy_test))\n","    np.save('stats_' + save_name+'_loss_train.npy', np.array(loss_train))\n","    # reload\n","    # loaded_data = np.load('data.npy').tolist()\n","\n","\n","    import matplotlib.pyplot as plt\n","\n","    def visualize_accuracy(accuracy_test, save_path):\n","        plt.figure(figsize=(10, 5))\n","        plt.plot(accuracy_test, marker='o', linestyle='-', color='b', label='Accuracy')\n","        plt.xlabel('Epochs')\n","        plt.ylabel('Accuracy of Test Set')\n","        plt.title('Accuracy Test Sequence')\n","        plt.legend()\n","        plt.grid(True)\n","        plt.savefig(save_path)\n","        plt.show()\n","\n","    visualize_accuracy(loss_train, 'fig_' + save_name + '_lost_train.png')\n","    visualize_accuracy(accuracy_test, 'fig_' + save_name + '_accuracy_test.png')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ======== run main function ===========\n","main(num_epochs = num_epochs, batch_size = batch_size, num_workers = num_workers, run_on_local = run_on_local, dataset1 = dataset1, model_id = model_id, optimizer_id = optimizer_id, data_aug = data_aug)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","1\n","2\n","3\n","4\n","5\n"]}],"source":["# trash code:\n","# link all dataset in kaggle to os.path\n","# import os\n","# for dirname, _, filenames in os.walk('/kaggle/input'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))\n","\n","\n","# optim_kwargs = dict(\n","#     lr=3e-4,\n","#     weight_decay=1e-6,\n","# )\n","\n","# ============================= old transoformation =============\n","# # preprocessing pipeline for input images\n","# transformation = dict()\n","# for data_type in (\"train\", \"test\"):\n","#     is_train = data_type==\"train\"\n","#     transformation[data_type] = tv_transforms.Compose(([\n","#         tv_transforms.RandomRotation(degrees=15),\n","#         tv_transforms.RandomHorizontalFlip(),\n","#         tv_transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n","#     ] if is_train else []) + \n","#     [\n","#         tv_transforms.ToTensor(),\n","#         tv_transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n","#     ])\n","\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":6698758,"sourceId":10794107,"sourceType":"datasetVersion"}],"dockerImageVersionId":30887,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.16"}},"nbformat":4,"nbformat_minor":4}

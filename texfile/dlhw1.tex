\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage[english]{babel}
\usepackage{latexsym,bm,amsmath,amssymb,graphicx,ctex,tikz,systeme,array, soul,scalerel,wrapfig,lipsum}
\newcommand*\circled[1]{\tikz[baseline=(char.base)]{
            \node[shape=circle,draw,inner sep=2pt] (char) {#1};}}
\usepackage{extarrows}% http://ctan.org/pkg/extarrows
\newcommand*{\vertbar}{\rule[-1ex]{0.5pt}{2.5ex}}
\newcommand*{\horzbar}{\rule[.5ex]{2.5ex}{0.5pt}}
\newcommand{\eqdef}{\xlongequal{\text{def}}}%
\usepackage{geometry}
 \geometry{
 a4paper,
 total={170mm,257mm},
 left=10mm,
 right=10mm,
 top=20mm,
 }
\usepackage{subfig}
\usepackage{wrapfig}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{graphicx}
\usepackage{titling}
\usepackage{listings}
\usepackage{xcolor}
\usepackage[lighttt]{lmodern}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\sffamily\large,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}
\newcommand{\subs}[1]{\subsection*{#1}}
\newcommand{\secs}[1]{\section*{#1}}
 
\usepackage{fancyhdr}
\fancypagestyle{plain}{%  the preset of fancyhdr 
    \fancyhf{} % clear all header and footer fields
    \fancyfoot[R]{Guyuan Xu\\224040074}
    \fancyfoot[L]{\thedate}
    \fancyhead[L]{MDS 5122 Deep Learning and Application}
    % \fancyhead[R]{\theauthor}
}
\makeatletter
\def\@maketitle{%
  \newpage
  \null
  \vskip 1em%
  \begin{center}%
  \let \footnote \thanks
    {\LARGE \@title \par}%
    \vskip 1em%
    %{\large \@date}%
  \end{center}%
  \par
  \vskip 1em}
\makeatother

% \usepackage{lipsum}  
% \usepackage{cmbright}



%======================================= document ======================================
%======================================= document ======================================
%======================================= document ======================================

\begin{document}
\title{\raggedright MDS 5122 Assignment 1}
%\author{Guyuan Xu \\224040074}
\date{March 9, 2025}
\maketitle

\noindent\begin{tabular}{@{}ll}
   Guyuan Xu &\href{mailto:224040074@link.cuhk.edu.cn}{224040074} \\
    
%
\end{tabular}

\secs{A. Build a Neural Network Using PyTorch}
\subs{1. reproducing example NeuralNetwork of example code A.}
\textcolor{blue}{check notebook}

\subs{2. Factors to improve accuracy}
In my experiment, I tried to use 1) Simple NN (which is the baseline model of example code A) and NN with more complex architecture (vgg16 and ResNet18/50); 2) adding BatchNorm layer and dropout layer; 3) different optimziers SGD and Adam with popular \textit{lr} or momentum params settings; 4) with/without data augmentation. \\

We mainly use the model of example code-A as our baseline model to examine how the above factors might affect accuracy. And due to computing resource limitation, i did not conduct strict experiment with strict variable controls. To gain insight is what we want.\\


\noindent\textbf{- BaseLine Model }: C3L3 (3 Conv layers + 3 Linear layers) on CIFAR-10 dataset\\
We first start with baseline model in example-code A, the steps of experiment are: 1)compare optimziers with all other settings the same, then pick the best optimziers (in terms of accuracy) for next step; 2) use the best optimizer and data augmentation to see if data augmentation could bring up accuracy in test set; 3) use best optimizer + data augmentation(note that data augmentation might not be useful, shall be given up if so) + \textcolor{red}{BatchNorm Layer} + \textcolor{red}{throw away dropout layer in convolution layer} to see whether we can have better accuracy on test set. 
\begin{verbatim}
  # our network architecture:  
  net = nn.Sequential(
      nn.Conv2d(3, 128, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3),
      nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3),
      nn.Conv2d(256, 512, 3, padding=1), nn.ReLU(inplace=True),
      nn.Conv2d(512, 512, 3, padding=1), nn.ReLU(inplace=True),
      nn.Conv2d(512, 256, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3),
      nn.Flatten(),
      nn.Linear(256 * 4 * 4, 512), nn.ReLU(inplace=True), nn.Dropout(0.5),
      nn.Linear(512, 256), nn.ReLU(inplace=True), nn.Dropout(0.5),
      nn.Linear(256, 128), nn.ReLU(inplace=True), nn.Dropout(0.5),
      nn.Linear(128, 10),
  )
  # Params count: 3*128*3*3+128*256*3*3+256*512*3*2*3+512**2*3*3+256*16*512+512*256+256*128+1280=7.28M

  # Using default data transformation in example code-A
  transformation = dict()
  for data_type in ("train", "test"):
    is_train = data_type=="train"
    transformation[data_type] = tv_transforms.Compose((
      [
        tv_transforms.RandomRotation(degrees=15),
        tv_transforms.RandomHorizontalFlip(),
        tv_transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),
      ] if is_train else []) + 
    [
        tv_transforms.ToTensor(),
        tv_transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),
    ])

  \end{verbatim}
This model is exactly the same model in example code A, we then try to reproduce the accuracy and comapre accuracy with different settings:
\begin{center}
  % 有可能多了一列, 另外用标红的一列表示baseline
  \begin{tabular}{|c|ccccc|c|} 
      \hline
      Model & & C3L3 & & & &   \\
      \hline
      Adam &  \textcolor{red}{ $\surd$ }   &  &  & &  &\\ 
      SGD & & $\surd$   & & &  &\\

      Data Aug& &  &  &  &  &\\

      dropout(conv) &\textcolor{red}{ $\surd$ } & $\surd$   & & &  & \\ 

      BatchNorm & & & &  &  & \\ 
      \hline
      Accuracy & \textcolor{red}{85.26} &84.93 & & & & \\
      \hline
  \end{tabular} 
\end{center}
\textcolor{red}{\# Note:} bacthsize = 32, Epoch num = 150, dropout(conv) indicate whether we use dropout layer in convlution layer.

\noindent - Conclusion: 
\begin{itemize}
  \item Data augmentation can greatly improve accuracy
  \item choosing SGD or Adam will not significantly affect accuracy, they just converge to almost the same accuracy at different speeds (in terms of epochs).
  \item BatchNorm
\end{itemize}

% ============== use advanced model structure: vgg16/resnet18/resnet50 ================






\subs{MNIST dataset}
We use simple CNN together with our best params on MNIST dataset. Check notebook codes.


\subs{Interesting findings and reflections}
1) visualize data after data augmentation
2) we have i learnt.


\secs{B. Build a Neural Network From Scratch}
做完1的试验后获取best 参数，接着用dezero堆叠一个相同结构。



\secs{Reflections}
\noindent\textbf{From BackwardPropagation to AutoGrad}: In example code part-B we can learn how forward pass and backward pass work together in a neural network, but implementing backward pass is complicated and sometimes impossible (especially in complicated computation). Meanwhile we know that all computation in deep learning are basically consist of few basic functions like exponents, add, subtract, multiplication etc, so we can utilizie chain rule to calculate gradient no matter how complicated a computation might be. This is how AutoGrad comes into play, and this is the core of  all deep learning frameworks, including pytorch.\\

\noindent\textbf{Understand by creating}: During the process of building a framework, i learn extensively and experience moments of revelation like "ah, this is how a neural network works!" or "so this algorithm can be implemented this way!" These insights are unattainable through merely using existing tools like pytorch. Some concepts can only be understood by creating, some truths can only be seen by building. 

For instance, some may view deep learning frameworks as mere libraries pieced together with layers and functions. In reality, frameworks go far beyond that. A framework can be considered a programming language—specifically, one with automatic differentiation capabilities (recently termed a "differentiable programming language").
















% \secs{A4.1 (Implementing the Gradient Method)}
% We want to minimize the objective function
% \[
% \min_{x\in\mathbb{R}^2} f(x) = \frac{1}{2}x_1^4-x_1^3-x_1^2+x_1^2x_2^2+\frac{1}{2}x_2^4-x_2^2
% \]
% by gradient descent methods with different initial points and stepsize strategies, as presented in the following.\\

% \noindent Initial points: 
% \[
% \chi^0 := \left\{
% \begin{bmatrix}
% -\frac{1}{2} \\ 1
% \end{bmatrix},
% \begin{bmatrix}
% -\frac{1}{2} \\ \frac{1}{2}
% \end{bmatrix},
% \begin{bmatrix}
% -\frac{1}{4} \\ -\frac{1}{2}
% \end{bmatrix},
% \begin{bmatrix}
% \frac{1}{2} \\ -\frac{1}{2}
% \end{bmatrix},
% \begin{bmatrix}
% \frac{1}{2} \\ 1
% \end{bmatrix}
% \right\}
% \]
% \noindent stationary points of $f(x)$:
% \[
% \chi^* := \left\{
% \begin{bmatrix}
% 0 \\ 0
% \end{bmatrix},
% \begin{bmatrix}
% 2 \\ 0
% \end{bmatrix},
% \begin{bmatrix}
% -\frac{1}{2} \\ 0
% \end{bmatrix},
% \begin{bmatrix}
% 0 \\ 1
% \end{bmatrix},
% \begin{bmatrix}
% 0 \\ -1
% \end{bmatrix}
% \right\}
% \]



% %------------ backtracking--------------
% \subsection*{1. Backtracking}
% % \begingroup
% % \setlength{\intextsep}{0pt}%
% % \setlength{\columnsep}{0pt}%
% % \begin{wrapfigure}{r}{0.65\textwidth}%靠文字内容的右侧
% %   \centering
% %   \includegraphics[width=\linewidth]{Back Tracking.png}
% %   \caption{Backtracking Line Search}
% % \end{wrapfigure}

% Back Tracking line search: choose the largest $\alpha_k \in \{\sigma^k: k = 0,1,...\}$ that satisfies Armijo condition $f(x_k+\alpha_k d_k)-f(x_k)\leq \gamma \alpha_k \nabla f(x_k)^T d_k$ with $(\sigma, \gamma) = (0.5,0.1)$.\\
% \\
% Performance (in terms of iteration) of Backtracking Line Search stepsize strategy are shown below:\\
% \\
%   \begin{tabular}{ccc}
    
%     \hline
%     $x_0$ & iteration & limit point $x^*$\\
%     \hline
%           (-0.50,1.00) & 13 & (2.00,-0.00)  \\ % backtrack
%           (-0.50,0.50) & 325 & (-0.00,1.00) \\ % backtrack
%           (-0.25,-0.50) & 467 & (-0.00,-1.00)  \\ % backtrack
%           (0.50,-0.50) & 12 & (2.00,0.00)  \\ % backtrack
%           (0.50,1.00) & 10 & (2.00,-0.00)  \\ % backtrack
%           \hline
%           \multicolumn{3}{c}{Backtracking Line Search}\\
%           \hline
%   \end{tabular}

% %   \endgroup
% \newpage
% %------------------ exact line search ----------------------
% \subs{2. Exact Line Search}

% % \begingroup
% % \setlength{\intextsep}{0pt}%
% % \setlength{\columnsep}{0pt}%
% % \begin{wrapfigure}{r}{0.65\textwidth}%靠文字内容的右侧
% %   \centering
% %   \includegraphics[width=\linewidth]{Exact Line Search.png}
% %   %\caption{Exact Line Search}
% % \end{wrapfigure}

% Exact Line Search: aim at choosing the stepsize $\alpha_k$ that 
% \[
% \alpha_k = \underset{\alpha_k \geq 0}{argmin}\; f(x_k+\alpha_k d_k)
% \]
% Performance of Exact line search stepsize strategy are shown below:\\

% \noindent\begin{tabular}{ccc}
    
%   \hline
%   $x_0$ & iteration & limit point $x^*$\\
%   \hline
%   (-0.50,1.00) & 295 & (-0.00,1.00)   \\ % exactlineS
%   (-0.50,0.50) & 296 & (-0.00,1.00)  \\ % exactlineS
%   (-0.25,-0.50) & 375 & (-0.00,-1.00)  \\ % exactlineS
%   (0.50,-0.50) & 9 & (2.00,0.00) \\ % exactlineS
%   (0.50,1.00) & 6 & (2.00,0.00)  \\ % exactlineS
%         \hline
%         \multicolumn{3}{c}{Exact Line Search}\\
%         \hline
% \end{tabular}\\
% \\
% \textbf{\# PS}: the paths of 2 consecutive steps are not perpendicular because we constraint $\alpha_k \leq 1$ (because we search $\alpha$ in $[0,a]$, where $a=1$) insetead of not setting any constraint to them.

% % \endgroup
% \vspace{1cm}

% %------------- diminishing -----------------
% \subs{3. Diminishing Stepsize}

% % \begingroup
% % \setlength{\intextsep}{0pt}%
% % \setlength{\columnsep}{0pt}%
% % \begin{wrapfigure}{r}{0.65\textwidth}%靠文字内容的右侧
% %   \centering
% %   \includegraphics[width=\linewidth]{Diminishing Stepsize.png}
% %   %\caption{Diminishing Stepsize}
% % \end{wrapfigure}

% \noindent Diminishing Stepsize: we simply set
% \[
%   \alpha_k = \frac{1}{\sqrt{k+2}}
% \]
% where $k$ is the round of iteration.\\
% Performance of diminishing stepsize strategy are shown below:

% \noindent\begin{tabular}{ccc}
    
%   \hline
%   $x_0$ & iteration & limit point $x^*$\\
%   \hline
%   (-0.50,1.00) & 47 & (2.00,0.00)  \\ % diminishing
%   (-0.50,0.50) & 8523 & (-0.00,1.00) \\ % diminishing
%   (-0.25,-0.50) & 8501 & (-0.00,-1.00)  \\ % diminishing
%   (0.50,-0.50) & 47 & (2.00,-0.00)  \\ % diminishing
%   (0.50,1.00) & 47 & (2.00,0.00)  \\ % diminishing
%         \hline
%         \multicolumn{3}{c}{Diminishing Stepsize}\\
%         \hline
% \end{tabular}\\
% \\
% \textbf{\# PS}: Since HW sheet has no requirement on $k$, we follow the common sense that $k$ starts from 1, so the first stepsize is
% \[
%   \alpha_1 = \frac{1}{\sqrt{1+2}} = \frac{1}{\sqrt{3}} 
% \]

% % \endgroup

% \newpage
% %------------- conclusion of stepsize strategy ---------------
% Then we can conclude the performance of different stepsize strategies as the following table:

  % \begin{center}
  %   \begin{tabular}{|c|cccc|} 
  %       \hline
  %       Methods & $x_0$ & iteration & limit point $x^*$ & Global Minimum?\\
  %       \hline
  %       &(-0.50,1.00) & 13 & (2.00,-0.00) & yes\\ % backtrack
  %       &(-0.50,0.50) & 325 & (-0.00,1.00) & no \\ % backtrack
  %       Back Tracking&(-0.25,-0.50) & 467 & (-0.00,-1.00) & no \\ % backtrack
  %       &(0.50,-0.50) & 12 & (2.00,0.00) & yes \\ % backtrack
  %       &(0.50,1.00) & 10 & (2.00,-0.00) & yes \\ % backtrack
  %       \hline
      %   \hline
      %   &(-0.50,1.00) & 295 & (-0.00,1.00) & no \\ % exactlineS
      %   &(-0.50,0.50) & 296 & (-0.00,1.00) & no \\ % exactlineS
      %   Exact Line Search&(-0.25,-0.50) & 375 & (-0.00,-1.00) & no \\ % exactlineS
      %   &(0.50,-0.50) & 9 & (2.00,0.00) & yes \\ % exactlineS
      %   &(0.50,1.00) & 6 & (2.00,0.00) & yes \\ % exactlineS
      %   \hline
      %   \hline
      %   &(-0.50,1.00) & 47 & (2.00,0.00) & yes\\ % diminishing
      %   &(-0.50,0.50) & 8523 & (-0.00,1.00) & no \\ % diminishing
      %   Diminishing Stepsize&(-0.25,-0.50) & 8501 & (-0.00,-1.00) & no \\ % diminishing
      %   &(0.50,-0.50) & 47 & (2.00,-0.00) & yes\\ % diminishing
      %   &(0.50,1.00) & 47 & (2.00,0.00) & yes \\ % diminishing
      % \hline
%     \end{tabular} 
% \end{center}
% \newpage

% % \secs{A4.2 (Inertial Gradient Method)}

% % \noindent The convergence trace of gradient method with momentum of $\beta \in \{0.3,0.5,0.7,0.9\}$ and different initial points are shown below respectively:\\
% % \vspace{5mm}

% % \noindent\includegraphics[width=0.5\linewidth]{GD with momentum, beta=03.png}
% % \includegraphics[width=0.5\linewidth]{GD with momentum, beta=05.png}\\
% % \includegraphics[width=0.5\linewidth]{GD with momentum, beta=07.png}
% % \includegraphics[width=0.5\linewidth]{GD with momentum, beta=09.png}\\

% \subs{Performance Analysis}
% by comparing the average iteration numbers of GD with momentum and GD with different stepsize strategies (discussed in part A4.1):
% \begin{center}
%   \begin{tabular}{c|ccc|cccc}
%     \hline
%     \multicolumn{1}{c}{} & \multicolumn{3}{c}{Stepsize strategies} & \multicolumn{4}{c}{GD with momentum}\\
%     \hline
%     &Backtrack & Exact LineSearch & Diminishing & $\beta = 0.3$ & $\beta = 0.5$ & $\beta = 0.7$ & $\beta = 0.9$\\
%     \hline
%     Average Iteration & 164.5 & 196.2 & 3433.0 & 104.8& 51.8 & 90.2 & 1250.0\\
%     \hline
%     Probablity to Global Min & 0.6 & 0.4 & 0.6 & 0.8 & 1.0 & 1.0 &0.8\\
%     \hline
%   \end{tabular}
% \end{center}
% It is easy to see that \textbf{the average iteration (averaging across 5 different initial points) it takes to converge to some limit point is noticeably larger using stepsize strategies than GD with momentum in general.}  \\
% \\
% And we also notice GD with momentum converger faster when $\beta$ change from $0.3$ to $0.5$, then converger slower when $\beta$ goes from $0.5$ to $0.9$, how to interpretate this phenomenon? we can first look at the detail of how $\beta$ affect convergence: 

% \begin{center}
%   \begin{tabular}{|c|cccc|} 
%       \hline
%       $\beta$ & $x_0$ & iteration & limit point $x^*$ & Global Minimum? \\
%       \hline
%       &(-0.50,1.00) & 26 & (2.00,0.00) & yes\\ % momentum beta 0.3
%       &(-0.50,0.50) & 33 & (2.00,-0.00) & yes \\ % momentum beta 0.3
%       $\beta = 0.3$&\textcolor{red}{(-0.25,-0.50)} & \textcolor{red}{417} & \textcolor{red}{(-0.00,-1.00)} & no \\ % momentum beta 0.3
%       &(0.50,-0.50) & 24 & (2.00,0.00) & yes \\ % momentum beta 0.3
%       &(0.50,1.00) & 24 & (2.00,0.00) & yes \\ % momentum beta 0.3
%       \hline
%       \hline
%       &(-0.50,1.00) & 39 & (2.00,0.00) & yes \\ % momentum beta 0.5
%       &(-0.50,0.50) & 56 & (2.00,0.00) & yes \\ % momentum beta 0.5
%       $\beta = 0.5$&(-0.25,-0.50) & 88 & (2.00,0.00) & yes \\ % momentum beta 0.5
%       &(0.50,-0.50) & 37 & (2.00,-0.00) & yes \\ % momentum beta 0.5
%       &(0.50,1.00) & 39 & (2.00,0.00) & yes \\ % momentum beta 0.5
%       \hline
%       \hline
%       &(-0.50,1.00) & 105 & (2.00,0.00) & yes \\ % momentum beta 0.7
%       &(-0.50,0.50) & 88 & (2.00,0.00) & yes \\ % momentum beta 0.7
%       $\beta = 0.7$&(-0.25,-0.50) & 102 & (2.00,-0.00) & yes \\ % momentum beta 0.7
%       &(0.50,-0.50) & 77 & (2.00,-0.00) & yes \\ % momentum beta 0.7
%       &(0.50,1.00) & 79 & (2.00,-0.00) & yes \\ % momentum beta 0.7
%     \hline
%     \hline
%     &(-0.50,1.00) & 268 & (2.00,0.00) & yes \\ % momentum beta 0.9
%     &(-0.50,0.50)& 258 & (2.00,0.00) & yes \\ % momentum beta 0.9
%     $\beta = 0.9$&(-0.25,-0.50) & 276 & (2.00,0.00) & yes \\ % momentum beta 0.9
%     &(0.50,-0.50) & 297 & (2.00,-0.00) & yes \\ % momentum beta 0.9
%     &\textcolor{red}{(0.50,1.00)} & \textcolor{red}{5151} & \textcolor{red}{(-0.00,1.00)} & no \\ % momentum beta 0.9
%     \hline
%   \end{tabular} 
% \end{center}
% Notice when $\beta = 0.3$ and starting from the initial point $(-0.25,-0.5)$, GD converge to $(0,-1)$ while other initial points all converge to $(2,0)$, this is because the first several stepsize of GD heppen to be too large from this initial point and \textbf{pushing the trace to an area not ideal for fast convergence}, and by coincidence the trace finally converge to a different limit point from the other initial points, and the iterations it takes to converge go very high, this should \textbf{be treated as an anomoly.} Same with $\beta = 0.9$ initial point $(0.5,1.0)$: this very initial condition just happen to be not ideal for fast convergence.\\
% After dropping this anomoly we can get an averge iteration number of $26.75$ for $\beta = 0.3$, and the trend becomes obvious: $\beta$ smaller, converge faster. \\
% \\
% Another observation is that \textbf{GD with momentum is more likely to converge to the global minimum} $(2,0)$ than GD with stepsize strategies, this is also easy to explain: with "momentum" (brought by the momentum term $\beta (x_k-k_{k-1})$), the trace is more likely to "escape" from the local minimum.
% \newpage





\end{document}


